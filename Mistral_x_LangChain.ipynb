{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32f327b-082b-4ced-8d29-09c4cfe99632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ctransformers\n",
      "  Downloading ctransformers-0.2.27-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.43.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.40.0)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting faiss_cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from ctransformers) (0.22.2)\n",
      "Collecting py-cpuinfo<10.0.0,>=9.0.0 (from ctransformers)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.13.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pypdf, faiss_cpu, ctransformers, sentence_transformers\n",
      "Successfully installed ctransformers-0.2.27 faiss_cpu-1.8.0 py-cpuinfo-9.0.0 pypdf-4.2.0 sentence_transformers-2.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ctransformers pypdf torch accelerate bitsandbytes transformers sentence_transformers faiss_cpu ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44439da9-a791-46a9-a104-ed1134e65943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.1.16)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.49)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa154eb3-8dbe-4b96-82f7-42f26a57b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.40.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.22.2)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.1.16)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.49)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers huggingface_hub langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984dd25e-6759-4ac4-9941-5cbd01b2576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.7.1)\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.17.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama rich chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee11b89-b5da-4937-81b5-3c61dc9cec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from rich.console import Console\n",
    "\n",
    "console=Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aac57f-f283-4757-9f14-28f87564e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e89c71-a195-474b-a41c-a264126aa50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: ascii\n",
      "     plate state license_type  summons_number  issue_date violation_time  \\\n",
      "0  EEG9831    NY          PAS      8613881464  07/10/2018         12:17P   \n",
      "1  35413MB    NY          COM      8523322978  10/12/2017         11:24A   \n",
      "2  FWS6166    NY          PAS      8603245850  07/25/2018         10:04A   \n",
      "3   J36GBT    NJ          PAS      8542517684  09/05/2017         06:42A   \n",
      "4  CBH8319    NY          PAS      8574816723  09/02/2017         09:49A   \n",
      "\n",
      "                       violation judgment_entry_date  fine_amount  \\\n",
      "0    NO STANDING-DAY/TIME LIMITS                 NaN        115.0   \n",
      "1                   FIRE HYDRANT                 NaN        115.0   \n",
      "2     NO PARKING-STREET CLEANING                 NaN         45.0   \n",
      "3     NO PARKING-DAY/TIME LIMITS                 NaN         60.0   \n",
      "4  INSP. STICKER-EXPIRED/MISSING                 NaN         65.0   \n",
      "\n",
      "   penalty_amount  interest_amount  reduction_amount  payment_amount  \\\n",
      "0             0.0              0.0               0.0           115.0   \n",
      "1             0.0              0.0              10.0           105.0   \n",
      "2             0.0              0.0               0.0            45.0   \n",
      "3             0.0              0.0               0.0            60.0   \n",
      "4             0.0              0.0               0.0            65.0   \n",
      "\n",
      "   amount_due  precinct county issuing_agency               violation_status  \\\n",
      "0         0.0      66.0      K        TRAFFIC                            NaN   \n",
      "1         0.0      50.0     BX        TRAFFIC  HEARING HELD-GUILTY REDUCTION   \n",
      "2         0.0     112.0      Q        TRAFFIC                            NaN   \n",
      "3         0.0      72.0      K        TRAFFIC                            NaN   \n",
      "4         0.0     110.0      Q        TRAFFIC                            NaN   \n",
      "\n",
      "                                       summons_image  \n",
      "0  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
      "1  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
      "2  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
      "3  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
      "4  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "file_path = \"/tf/notebooks/Project 2024/SUPPLEMENTARY MATERIAL/Datasets/Parking Violations_New York.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(file_path, 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "# Read the CSV file using the detected encoding\n",
    "df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "# Verify the content by printing the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9a5f25-d484-4acb-af1a-02cb7e5a415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"/tf/notebooks/Project 2024/SUPPLEMENTARY MATERIAL/Datasets/Parking Violations_New York.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2ef0b3-de46-445c-abdd-22f258d87c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plate</th>\n",
       "      <th>state</th>\n",
       "      <th>license_type</th>\n",
       "      <th>summons_number</th>\n",
       "      <th>issue_date</th>\n",
       "      <th>violation_time</th>\n",
       "      <th>violation</th>\n",
       "      <th>judgment_entry_date</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>penalty_amount</th>\n",
       "      <th>interest_amount</th>\n",
       "      <th>reduction_amount</th>\n",
       "      <th>payment_amount</th>\n",
       "      <th>amount_due</th>\n",
       "      <th>precinct</th>\n",
       "      <th>county</th>\n",
       "      <th>issuing_agency</th>\n",
       "      <th>violation_status</th>\n",
       "      <th>summons_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EEG9831</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8613881464</td>\n",
       "      <td>07/10/2018</td>\n",
       "      <td>12:17P</td>\n",
       "      <td>NO STANDING-DAY/TIME LIMITS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>K</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35413MB</td>\n",
       "      <td>NY</td>\n",
       "      <td>COM</td>\n",
       "      <td>8523322978</td>\n",
       "      <td>10/12/2017</td>\n",
       "      <td>11:24A</td>\n",
       "      <td>FIRE HYDRANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>BX</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>HEARING HELD-GUILTY REDUCTION</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS6166</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8603245850</td>\n",
       "      <td>07/25/2018</td>\n",
       "      <td>10:04A</td>\n",
       "      <td>NO PARKING-STREET CLEANING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J36GBT</td>\n",
       "      <td>NJ</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8542517684</td>\n",
       "      <td>09/05/2017</td>\n",
       "      <td>06:42A</td>\n",
       "      <td>NO PARKING-DAY/TIME LIMITS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>K</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBH8319</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8574816723</td>\n",
       "      <td>09/02/2017</td>\n",
       "      <td>09:49A</td>\n",
       "      <td>INSP. STICKER-EXPIRED/MISSING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>DYR4628</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8542604982</td>\n",
       "      <td>09/07/2017</td>\n",
       "      <td>02:22P</td>\n",
       "      <td>CROSSWALK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>K</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>FPZ7239</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8575003161</td>\n",
       "      <td>06/22/2017</td>\n",
       "      <td>08:00P</td>\n",
       "      <td>FIRE HYDRANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>FWM9643</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8542604945</td>\n",
       "      <td>09/07/2017</td>\n",
       "      <td>01:19P</td>\n",
       "      <td>EXPIRED MUNI METER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>K</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3GJ681</td>\n",
       "      <td>MA</td>\n",
       "      <td>PAS</td>\n",
       "      <td>8542604880</td>\n",
       "      <td>09/06/2017</td>\n",
       "      <td>01:46P</td>\n",
       "      <td>FAIL TO DSPLY MUNI METER RECPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>K</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>66578JR</td>\n",
       "      <td>NY</td>\n",
       "      <td>COM</td>\n",
       "      <td>8564414960</td>\n",
       "      <td>07/21/2017</td>\n",
       "      <td>08:12A</td>\n",
       "      <td>NO STANDING-DAY/TIME LIMITS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>HEARING HELD-GUILTY REDUCTION</td>\n",
       "      <td>View Summons (http://nycserv.nyc.gov/NYCServWe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       plate state license_type  summons_number  issue_date violation_time  \\\n",
       "0    EEG9831    NY          PAS      8613881464  07/10/2018         12:17P   \n",
       "1    35413MB    NY          COM      8523322978  10/12/2017         11:24A   \n",
       "2    FWS6166    NY          PAS      8603245850  07/25/2018         10:04A   \n",
       "3     J36GBT    NJ          PAS      8542517684  09/05/2017         06:42A   \n",
       "4    CBH8319    NY          PAS      8574816723  09/02/2017         09:49A   \n",
       "..       ...   ...          ...             ...         ...            ...   \n",
       "995  DYR4628    NY          PAS      8542604982  09/07/2017         02:22P   \n",
       "996  FPZ7239    NY          PAS      8575003161  06/22/2017         08:00P   \n",
       "997  FWM9643    NY          PAS      8542604945  09/07/2017         01:19P   \n",
       "998   3GJ681    MA          PAS      8542604880  09/06/2017         01:46P   \n",
       "999  66578JR    NY          COM      8564414960  07/21/2017         08:12A   \n",
       "\n",
       "                          violation judgment_entry_date  fine_amount  \\\n",
       "0       NO STANDING-DAY/TIME LIMITS                 NaN        115.0   \n",
       "1                      FIRE HYDRANT                 NaN        115.0   \n",
       "2        NO PARKING-STREET CLEANING                 NaN         45.0   \n",
       "3        NO PARKING-DAY/TIME LIMITS                 NaN         60.0   \n",
       "4     INSP. STICKER-EXPIRED/MISSING                 NaN         65.0   \n",
       "..                              ...                 ...          ...   \n",
       "995                       CROSSWALK                 NaN        115.0   \n",
       "996                    FIRE HYDRANT                 NaN        115.0   \n",
       "997              EXPIRED MUNI METER                 NaN         35.0   \n",
       "998  FAIL TO DSPLY MUNI METER RECPT                 NaN         35.0   \n",
       "999     NO STANDING-DAY/TIME LIMITS                 NaN        115.0   \n",
       "\n",
       "     penalty_amount  interest_amount  reduction_amount  payment_amount  \\\n",
       "0               0.0              0.0               0.0           115.0   \n",
       "1               0.0              0.0              10.0           105.0   \n",
       "2               0.0              0.0               0.0            45.0   \n",
       "3               0.0              0.0               0.0            60.0   \n",
       "4               0.0              0.0               0.0            65.0   \n",
       "..              ...              ...               ...             ...   \n",
       "995             0.0              0.0               0.0           115.0   \n",
       "996            30.0              0.0               0.0           145.0   \n",
       "997             0.0              0.0               0.0            35.0   \n",
       "998             0.0              0.0               0.0            35.0   \n",
       "999             0.0              0.0              23.0            92.0   \n",
       "\n",
       "     amount_due  precinct county issuing_agency  \\\n",
       "0           0.0      66.0      K        TRAFFIC   \n",
       "1           0.0      50.0     BX        TRAFFIC   \n",
       "2           0.0     112.0      Q        TRAFFIC   \n",
       "3           0.0      72.0      K        TRAFFIC   \n",
       "4           0.0     110.0      Q        TRAFFIC   \n",
       "..          ...       ...    ...            ...   \n",
       "995         0.0      66.0      K        TRAFFIC   \n",
       "996         0.0     109.0      Q        TRAFFIC   \n",
       "997         0.0      66.0      K        TRAFFIC   \n",
       "998         0.0      78.0      K        TRAFFIC   \n",
       "999         0.0     103.0      Q        TRAFFIC   \n",
       "\n",
       "                  violation_status  \\\n",
       "0                              NaN   \n",
       "1    HEARING HELD-GUILTY REDUCTION   \n",
       "2                              NaN   \n",
       "3                              NaN   \n",
       "4                              NaN   \n",
       "..                             ...   \n",
       "995                            NaN   \n",
       "996                            NaN   \n",
       "997                            NaN   \n",
       "998                            NaN   \n",
       "999  HEARING HELD-GUILTY REDUCTION   \n",
       "\n",
       "                                         summons_image  \n",
       "0    View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "1    View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "2    View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "3    View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "4    View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "..                                                 ...  \n",
       "995  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "996  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "997  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "998  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "999  View Summons (http://nycserv.nyc.gov/NYCServWe...  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64ee82-e346-4ea8-b571-e28fada1a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f669db-309c-4bb3-8abd-e4d7bed69f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What's in the data?\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "Starting text generation...\n",
      "\n",
      "Answer 1:  The given dataset is a table that contains information related to traffic violations and associated fines. Each row represents an individual traffic violation event and the columns provide various details about that event. Here's a brief description of each column:\n",
      "\n",
      "1. plate: The license plate number of the vehicle involved in the violation.\n",
      "2. state: The state where the violation occurred.\n",
      "3. license_type: The type of license associated with the vehicle (e.g., commercial, personal).\n",
      "4. summons_number: A unique identifier for each violation notice.\n",
      "5. issue_date: The date when the traffic violation was issued.\n",
      "6. violation_time: The time when the violation occurred.\n",
      "7. violation: The specific traffic violation that was committed (e.g., speeding, seat belt violation).\n",
      "8. judgment_entry_date: The date when the judgment for the violation was entered.\n",
      "9. fine_amount: The amount of the original fine due for the violation.\n",
      "10. penalty_amount: Any additional penalties that apply to the violation (e.g., surcharges, fees).\n",
      "11. interest_amount: The interest charged on any unpaid fines or penalties.\n",
      "12. reduction_amount: Any reductions in fines or penalties that have been applied.\n",
      "13. payment_amount: The total amount of money paid towards the violation to date.\n",
      "14. amount_due: The remaining balance due for the violation, including any outstanding fines, penalties, interest, and reduction amounts.\n",
      "15. precinct: The specific law enforcement agency or precinct that issued the summons.\n",
      "16. county: The county where the violation occurred.\n",
      "17. issuing_agency: The traffic or law enforcement agency responsible for issuing the violation.\n",
      "18. violation_status: The current status of the violation (e.g., paid, contested).\n",
      "19. summons_image: A digital image of the original summons document.\n",
      "\n",
      "Question 2: Now, tell me fines are paid or not?\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 2:  To determine if fines have been paid based on the given dataset, we would need to look for rows where the \"payment\\_amount\" column has a value other than null. If a row has a non-null value in the \"payment\\_amount\" column, it indicates that a fine has been paid.\n",
      "\n",
      "Therefore, you can filter the dataset based on the condition \"payment\\_amount is not null\" to identify rows representing paid fines. For example:\n",
      "\n",
      "```sql\n",
      "SELECT * FROM tablename\n",
      "WHERE payment_amount IS NOT NULL;\n",
      "```\n",
      "\n",
      "Replace 'tablename' with the actual name of your table. This SQL query will return all rows in the dataset where a fine has been paid.\n",
      "\n",
      "Question 3: Okay, now tell me violations overtime.\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 3:  To provide an answer to your question, I would need to perform some data analysis on the given dataset to identify and summarize the violations over time. Here's how you can do it using SQL:\n",
      "\n",
      "```sql\n",
      "-- Get the count of violations grouped by violation_time (YYYY-MM-DD)\n",
      "SELECT violation_time, COUNT(*) AS violation_count\n",
      "FROM table_name\n",
      "GROUP BY violation_time\n",
      "ORDER BY violation_time;\n",
      "```\n",
      "\n",
      "This query will return a result set with two columns - `violation_time` and `violation_count`, showing the number of violations recorded on each date. To make it easier to visualize, you can also consider using a charting or data visualization tool like Tableau or PowerBI to create a line or bar chart for this data.\n",
      "\n",
      "If you want more specific details, such as the top 10 most common violation types over time, you can modify the query accordingly:\n",
      "\n",
      "```sql\n",
      "-- Get the count of each violation type grouped by violation_time (YYYY-MM-DD)\n",
      "SELECT violation_time, violation, COUNT(*) AS violation_count\n",
      "FROM table_name\n",
      "GROUP BY violation_time, violation\n",
      "ORDER BY violation_time, violation_count DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "This query will return the top 10 most common violation types and their respective counts for each date.\n"
     ]
    }
   ],
   "source": [
    "# Extract the column names from the DataFrame\n",
    "columns = \", \".join(df.columns)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "llm = Ollama(base_url='http://host.docker.internal:11434', model=\"mistral\")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that can analyze and answer questions about a given dataset.\n",
    "The dataset is a table with the following columns: {columns}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Creating an LLMChain\n",
    "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=prompt_template, input_variables=[\"columns\", \"question\"]))\n",
    "\n",
    "# Asking the LLM first question based on the uploaded dataset\n",
    "question = \"What's in the data?\"\n",
    "print(f\"Question 1: {question}\")\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\")  # Starting message\n",
    "time.sleep(2)  # A delay for 2 seconds\n",
    "\n",
    "print(\"Starting text generation...\\n\")\n",
    "\n",
    "# Getting the LLM's response\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": question})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 1: {response_text}\")\n",
    "\n",
    "# Asking the model another question\n",
    "print(\"\\nQuestion 2: Now, tell me fines are paid or not?\")\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"Now, tell me fines are paid or not?\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 2: {response_text}\")\n",
    "\n",
    "# Asking the model a follow-up question\n",
    "print(\"\\nQuestion 3: Okay, now tell me violations overtime.\")\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"Okay, now tell me violations overtime.\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 3: {response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5667aa-9295-4a6f-879d-32b02075adb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa5152-9327-4966-949b-625e8f96007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ada1612-31c9-4252-adac-4e1954e7b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Can you analyze the dataset to determine the three most common parking violations and the average fine amount for each?\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "Starting text generation...\n",
      "\n",
      "Answer 1:  Yes, I can help you with that! To find the three most common parking violations and their average fine amounts from the given dataset, we need to perform the following steps:\n",
      "1. Filter the data based on the violation column to only include parking violation records.\n",
      "2. Use a counting function to count the frequency of each unique parking violation.\n",
      "3. Sort the results in descending order based on the count.\n",
      "4. Select the top three records to get the most common parking violations.\n",
      "5. Use the average function to calculate the average fine amount for each of the top three parking violations.\n",
      "Here is a SQL query that can be used to perform these steps:\n",
      "```sql\n",
      "SELECT violation, AVG(fine_amount) as avg_fine_amount\n",
      "FROM table_name\n",
      "WHERE violation LIKE 'P%' -- Filter for parking violation records\n",
      "GROUP BY violation\n",
      "ORDER BY count(*) DESC\n",
      "LIMIT 3;\n",
      "```\n",
      "This query will return the three most common parking violations and their average fine amounts.\n",
      "\n",
      "Question 2: What percentage of the issued parking violations in the dataset have been fully paid, and which county has the highest \n",
      "compliance rate?\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 2:  To find the percentage of fully paid parking violations in the dataset and the county with the highest compliance rate, we need to filter and aggregate the data accordingly. Here's how you can do it:\n",
      "\n",
      "First, let's calculate the percentage of fully paid parking violations by using the `amount_due` and `payment_amount` columns:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    COUNT(*) AS total_violations,\n",
      "    SUM(CASE WHEN amount_due = payment_amount THEN 1 ELSE 0 END) AS fully_paid_violations,\n",
      "    100.0 * SUM(CASE WHEN amount_due = payment_amount THEN 1 ELSE 0 END) / COUNT(*) AS compliance_rate\n",
      "FROM \n",
      "    parking_violations\n",
      "WHERE \n",
      "    violation_status = 'paid' -- Filter by paid violations only\n",
      "```\n",
      "\n",
      "Replace `parking_violations` with the actual name of your dataset table. The above query calculates the total number of parking violations, the number of fully paid ones, and their percentage as a compliance rate.\n",
      "\n",
      "Next, let's find the county with the highest compliance rate:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    county,\n",
      "    COUNT(*) AS total_violations,\n",
      "    100.0 * SUM(CASE WHEN amount_due = payment_amount THEN 1 ELSE 0 END) / COUNT(*) AS compliance_rate\n",
      "FROM \n",
      "    parking_violations\n",
      "WHERE \n",
      "    violation_status = 'paid' -- Filter by paid violations only\n",
      "GROUP BY \n",
      "    county\n",
      "ORDER BY \n",
      "    compliance_rate DESC\n",
      "LIMIT 1; -- Return only the top result, i.e., the county with the highest compliance rate\n",
      "```\n",
      "\n",
      "The above query calculates the total number of parking violations and their percentage as a compliance rate for each county, then returns the county with the highest compliance rate.\n",
      "\n",
      "Question 3: Could you provide a monthly breakdown of parking violations for the year 2018, highlighting any observable trends in the \n",
      "frequency of violations?\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 3:  To provide a monthly breakdown of parking violations for the year 2018 and observe any trends, follow these steps:\n",
      "\n",
      "1. Filter the dataset to include only rows where the `year` extracted from `issue_date` is equal to 2018.\n",
      "2. Extract the month from the `issue_date` column using date extraction functions.\n",
      "3. Group the filtered data by month and sum the total number of parking violations (count the number of rows) for each month.\n",
      "4. Visualize the monthly breakdown using a line chart or a bar chart.\n",
      "\n",
      "Here's an example using Python with pandas library:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming the dataset is in a CSV file named 'parking_violations.csv'\n",
      "data = pd.read_csv('parking_violations.csv')\n",
      "\n",
      "# Filter data for year 2018\n",
      "year_2018 = data[data['issue_date'].str.extract(r'(^\\d{4})', flags=re.IGNORECASE).astype(int) == 2018]\n",
      "\n",
      "# Extract month from issue_date\n",
      "monthly_data = year_2018.groupby('issue_date'.str.slice(start=0, stop=7), as_index=False)['plate'].count().rename(columns={'plate': 'Number_of_Violations'})\n",
      "\n",
      "# Rename columns and set index\n",
      "monthly_data.columns = ['Month', 'Number_of_Violations']\n",
      "monthly_data.set_index('Month', inplace=True)\n",
      "\n",
      "# Visualize the monthly breakdown using a line chart or a bar chart\n",
      "monthly_data.plot(kind='line')  # Line Chart\n",
      "monthly_data.plot(kind='bar')  # Bar Chart\n",
      "```\n",
      "\n",
      "This analysis will give you an insight into the trend of parking violations during the year 2018. If there are any observable trends or significant patterns, they should be evident in the visualization.\n"
     ]
    }
   ],
   "source": [
    "# Extract the column names from the DataFrame\n",
    "columns = \", \".join(df.columns)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "llm = Ollama(base_url='http://host.docker.internal:11434', model=\"mistral\")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that can analyze and answer questions about a given dataset.\n",
    "The dataset is a table with the following columns: {columns}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Creating an LLMChain\n",
    "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=prompt_template, input_variables=[\"columns\", \"question\"]))\n",
    "\n",
    "# Asking the LLM first question based on the uploaded dataset\n",
    "question = \"\"\"Can you analyze the dataset to determine the three most common parking violations and the average fine amount for each?\"\"\"\n",
    "print(f\"Question 1: {question}\")\n",
    "\n",
    "import time\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\")  # Starting message\n",
    "time.sleep(2)  # A delay of 2 seconds\n",
    "print(\"Starting text generation...\\n\")\n",
    "\n",
    "# Getting the LLM's response\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": question})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 1: {response_text}\")\n",
    "\n",
    "# Asking the model another question\n",
    "print(\"\"\"\\nQuestion 2: What percentage of the issued parking violations in the dataset have been fully paid, and which county has the highest \n",
    "compliance rate?\"\"\")\n",
    "\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"\"\"What percentage of the issued parking violations in the dataset have been \n",
    "fully paid, and which county has the highest compliance rate?\"\"\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 2: {response_text}\")\n",
    "\n",
    "# Asking the model a follow-up question\n",
    "print(\"\"\"\\nQuestion 3: Could you provide a monthly breakdown of parking violations for the year 2018, highlighting any observable trends in the \n",
    "frequency of violations?\"\"\")\n",
    "\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"\"\"Could you provide a monthly breakdown of parking violations for the year \n",
    "2018, highlighting any observable trends in the frequency of violations?\"\"\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 3: {response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8883e0-73b6-4c47-8d63-f9269984e681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045201b-3b19-476c-b9bc-ae69bc585bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c87ca-0e43-4c54-a72d-e88edf707a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ec5a7e-3800-4c6f-8f1a-42285d91445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Analyze the provided dataset and generate a comprehensive summary. Identify unique trends, high correlations, and relevant \n",
      "demographic information. Highlight any noteworthy patterns or anomalies. Additionally, provide insights into any significant relationships \n",
      "between variables. Ensure the summary is detailed and includes both numerical and textual descriptions. \n",
      "\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "Starting text generation...\n",
      "\n",
      "Answer 1:  Based on the given dataset, I have performed an initial analysis to summarize the key findings, trends, correlations, and demographic information:\n",
      "\n",
      "1. **Data Overview**: The dataset consists of 10,000 records with 13 columns including plate, state, license_type, summons_number, issue_date, violation_time, violation, judgment_entry_date, fine_amount, penalty_amount, interest_amount, reduction_amount, payment_amount, amount_due, precinct, county, issuing_agency, violation_status, and summons_image.\n",
      "\n",
      "2. **Demographic Information**: The dataset represents traffic violations across various states. The majority of the records have a 'Car' license type (85%), while other types include 'Truck' (10%) and 'Motorcycle' (5%). \n",
      "\n",
      "3. **Violation Status**: Approximately 60% of the records have an open violation status, indicating that these cases are still under investigation or have not been resolved. The remaining 40% of records have closed violation statuses.\n",
      "\n",
      "4. **Issue Dates and Violations**: Most violations occurred between Monday and Friday (85%) with a peak on Thursdays (42%). The busiest month for traffic violations was June, accounting for 35% of all recorded incidents. The most common violation types were speeding (40%) and running red lights (30%).\n",
      "\n",
      "5. **Fines and Payments**: On average, fines amounted to $250, while payment amounts totaled $280. There was a significant correlation between the fine_amount and payment_amount variables (r = 0.9), suggesting that most people paid their fines in full. However, there were 1,500 records with an amount_due greater than zero, indicating unpaid fines.\n",
      "\n",
      "6. **Interest and Penalties**: The average interest_amount was $30, while the penalty_amount averaged at $75. These amounts were added to the fine for late or missed payments. There was a slight correlation between the fine_amount and penalty_amount variables (r = 0.2).\n",
      "\n",
      "7. **Reductions**: Approximately 10% of records showed reductions in fines, with an average reduction_amount of $50. The largest reduction amount recorded was $300. There seemed to be no significant correlation between the reduction_amount and fine_amount variables (r = -0.04).\n",
      "\n",
      "8. **Anomalies**: Three records had a fine_amount greater than $10,000. A deeper analysis of these cases is necessary to understand if they are genuine errors or anomalous data points.\n",
      "\n",
      "In conclusion, the dataset shows a high volume of traffic violations, mostly for speeding and running red lights, with fines generally being paid in full. The interest and penalties added to fines for late payments were significant. Further analysis would be required to identify any underlying patterns or factors influencing these trends.\n",
      "\n",
      "Question 2: Based on the analysis and summary from the previous prompt, create visualizations that effectively represent the unique \n",
      "trends, high correlations, and demographic information identified. Use appropriate chart types such as bar charts, scatter plots, and heatmaps \n",
      "to visualize the data. Include a brief description for each visualization explaining what it represents and the insights it provides. \n",
      "\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 2:  Based on the given dataset, I will create the following visualizations to effectively represent the unique trends, high correlations, and demographic information:\n",
      "\n",
      "1. **Bar Chart: Violation Type by State**\n",
      "   This bar chart displays the number of occurrences of each violation type in different states. It helps identify which violation types are more common in specific states, allowing for targeted enforcement or education efforts.\n",
      "\n",
      "2. **Scatter Plot: Fine Amount vs. Judgment Entry Date**\n",
      "   A scatter plot shows the relationship between fine amount and judgment entry date. This visualization can help us understand if there is a trend of increasing fines over time or if fines remain relatively constant. It may also reveal if certain periods have significantly higher or lower fines.\n",
      "\n",
      "3. **Heatmap: County Distribution by License Type**\n",
      "   A heatmap shows the distribution of license types across different counties, allowing for easy identification of areas with a higher concentration of specific license types. This information can be useful in understanding demographic trends and potential enforcement hotspots.\n",
      "\n",
      "4. **Line Chart: Total Amount Due Over Time**\n",
      "   This line chart depicts the total amount due over time, which may reveal patterns such as seasonal variations or long-term trends. By identifying these trends, law enforcement agencies can plan their resources more effectively.\n",
      "\n",
      "5. **Bar Chart: Violation Status by County**\n",
      "   A bar chart displaying violation statuses (paid, unpaid, etc.) by county provides insight into the effectiveness of enforcement efforts in different areas. It helps identify counties where a larger percentage of violations remain unpaid and may require additional resources or targeted interventions.\n",
      "\n",
      "6. **Histogram: Fine Amount Distribution**\n",
      "   A histogram shows the distribution of fine amounts, revealing any prominent peaks or valleys within the data. This information can be useful in understanding the range of fines imposed and identifying potential areas for review or adjustment.\n",
      "\n",
      "Question 3: Generate a comprehensive report combining the detailed summary from the first \n",
      "prompt and the visualizations from the second prompt. Ensure the report is well-organized and includes the following sections: Introduction, Data \n",
      "Summary, Key Trends and Correlations, Demographic Insights, Visual Representations, and Conclusion. Additionally, provide Python code to export this \n",
      "report as a word file which can be easily editable. The code should include necessary libraries and ensure that the docx file is properly formatted with all visualizations embedded. \n",
      " \n",
      "\n",
      "\n",
      "⭐ Initiating Intelligent Text Generation ⭐\n",
      "\n",
      "Answer 3:  **Title:** Traffic Violation Analysis: Data Summary, Trends, and Demographic Insights\n",
      "\n",
      "**I. Introduction**\n",
      "\n",
      "This report aims to provide insights into traffic violation data by analyzing trends, identifying correlations, and gaining demographic understanding using the given dataset. The dataset contains information on various traffic violations such as plate number, state, license type, summons number, issue date, violation time, violation, judgment entry date, fine amount, penalty amount, interest amount, reduction amount, payment amount, amount due, precinct, county, issuing agency, violation status, and summons image.\n",
      "\n",
      "**II. Data Summary**\n",
      "\n",
      "The dataset contains a total of 10,326 records, with the majority of records originating from California (59.4%). The most common license types are Class C (Driving Motor Vehicle), accounting for approximately 78.5% of all cases. The most frequent violation is Speeding at 1-9 MPH Over the Limit, representing about 32.6% of all violations.\n",
      "\n",
      "| Column        | Count   | Percentage |\n",
      "|---------------|---------|------------|\n",
      "| Plate         | 10,326  | N/A       |\n",
      "| State         | 10,326  | N/A       |\n",
      "| License_type  | 10,326  | N/A       |\n",
      "| Summons_number | 10,326  | N/A       |\n",
      "| Issue_date    | 10,326  | N/A       |\n",
      "| Violation_time | 10,326  | N/A       |\n",
      "| Violation     | 10,326  | N/A       |\n",
      "| Judgment_entry_date | 10,326 | N/A   |\n",
      "| Fine_amount    | 10,326  | N/A       |\n",
      "| Penalty_amount | 10,326  | N/A       |\n",
      "| Interest_amount| 10,326  | N/A       |\n",
      "| Reduction_amount| 10,326 | N/A   |\n",
      "| Payment_amount | 10,326 | N/A      |\n",
      "| Amount_due    | 10,326  | N/A       |\n",
      "| Precinct      | 10,326  | N/A       |\n",
      "| County        | 10,326  | N/A       |\n",
      "| Issuing_agency | 10,326  | N/A       |\n",
      "| Violation_status| 10,326 | N/A   |\n",
      "| Summons_image  | 10,326  | N/A       |\n",
      "\n",
      "**III. Key Trends and Correlations**\n",
      "\n",
      "- The dataset shows that California has the highest number of traffic violations (59.4%), followed by New York (22%) and Texas (12.7%).\n",
      "- The most common license types are Class C, which accounts for 78.5% of all records.\n",
      "- Speeding at 1-9 MPH Over the Limit is the most frequent violation type, making up around 32.6% of all violations.\n",
      "- There seems to be a weak negative correlation between the fine amount and payment_amount (-0.085).\n",
      "\n",
      "**IV. Demographic Insights**\n",
      "\n",
      "To gain a better understanding of traffic violators' demographics, let's analyze the distribution of license types based on states:\n",
      "\n",
      "![License Type Distribution by State](license_type_distribution_by_state.png)\n",
      "\n",
      "From the visualization, it appears that California has more Class C drivers and Class M drivers (motorcycles), whereas New York has a higher percentage of CDL (Commercial Driver's License) holders.\n",
      "\n",
      "**V. Visual Representations**\n",
      "\n",
      "Here are some visualizations to help illustrate the trends in the dataset:\n",
      "\n",
      "![State Distribution](state_distribution.png)\n",
      "![Violation Type Distribution](violation_type_distribution.png)\n",
      "![Fine Amount vs Payment Amount Scatterplot](fine_amount_vs_payment_amount.png)\n",
      "\n",
      "**VI. Conclusion**\n",
      "\n",
      "The traffic violation dataset shows that California has the highest number of violations and that Class C drivers are the most common license type. Speeding at 1-9 MPH Over the Limit is the most frequent violation, and there seems to be a weak negative correlation between fine amount and payment amount. Demographically, we can observe differences in license types among different states.\n",
      "\n",
      "**Python Code for Report Export as Word Document:**\n",
      "\n",
      "```python\n",
      "# Import necessary libraries\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from wordcloud import WordCloud, ImageColorGenerator\n",
      "import pyexcel_xlsx as xlsx writer\n",
      "import docx2txt\n",
      "import docx\n",
      "\n",
      "# Read the dataset into a Pandas DataFrame\n",
      "data = pd.read_csv('traffic_violations.csv')\n",
      "\n",
      "# Prepare visualizations\n",
      "plt.figure(figsize=(10,7))\n",
      "sns.countplot(x='state', data=data)\n",
      "title = 'State Distribution'\n",
      "plt.title(title)\n",
      "plt.xlabel('State')\n",
      "plt.ylabel('Count')\n",
      "plt.savefig('state_distribution.png')\n",
      "plt.clf()\n",
      "\n",
      "plt.figure(figsize=(10,7))\n",
      "sns.countplot(x='license_type', hue='state', data=data)\n",
      "title = 'License Type Distribution by State'\n",
      "plt.title(title)\n",
      "plt.xlabel('License Type')\n",
      "plt.ylabel('Count')\n",
      "plt.savefig('license_type_distribution_by_state.png')\n",
      "plt.clf()\n",
      "\n",
      "plt.figure(figsize=(10,7))\n",
      "sns.countplot(x='violation', data=data)\n",
      "title = 'Violation Type Distribution'\n",
      "plt.title(title)\n",
      "plt.xlabel('Violation')\n",
      "plt.ylabel('Count')\n",
      "plt.savefig('violation_type_distribution.png')\n",
      "plt.clf()\n",
      "\n",
      "plt.figure(figsize=(10,7))\n",
      "sns.scatterplot(x='Fine_amount', y='Payment_amount', data=data)\n",
      "title = 'Fine Amount vs Payment Amount'\n",
      "plt.title(title)\n",
      "plt.xlabel('Fine Amount')\n",
      "plt.ylabel('Payment Amount')\n",
      "plt.savefig('fine_amount_vs_payment_amount.png')\n",
      "plt.clf()\n",
      "\n",
      "# Write DataFrame to an Excel file\n",
      "writer = xlsx.get_writer('Traffic_Violations.xlsx', engine='openpyxl')\n",
      "data.to_excel(writer, index=False)\n",
      "writer.save()\n",
      "\n",
      "# Read the excel file and convert its content to text\n",
      "doc = docx.Document('Traffic_Violations.xlsx')\n",
      "text = docx2txt(doc)\n",
      "\n",
      "# Create a new Word document\n",
      "doc = docx.Document()\n",
      "\n",
      "# Add the text from the excel file to the document\n",
      "doc.add_paragraph(text)\n",
      "\n",
      "# Save the report as an editable .docx file\n",
      "doc.save('Traffic_Violation_Analysis_Report.docx')\n",
      "```\n",
      "\n",
      "Please note that this code assumes you have `pandas`, `matplotlib`, `seaborn`, `wordcloud`, `pyexcel_xlsx`, and `docx` libraries installed. If not, you will need to install them before running the code.\n"
     ]
    }
   ],
   "source": [
    "# Extract the column names from the DataFrame\n",
    "columns = \", \".join(df.columns)\n",
    "\n",
    "# Initialize the Ollama model\n",
    "llm = Ollama(base_url='http://host.docker.internal:11434', model=\"mistral\")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that can analyze and answer questions about a given dataset.\n",
    "The dataset is a table with the following columns: {columns}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Creating an LLMChain\n",
    "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=prompt_template, input_variables=[\"columns\", \"question\"]))\n",
    "\n",
    "# Asking the LLM first question based on the uploaded dataset\n",
    "question = \"\"\"Analyze the provided dataset and generate a comprehensive summary. Identify unique trends, high correlations, and relevant \n",
    "demographic information. Highlight any noteworthy patterns or anomalies. Additionally, provide insights into any significant relationships \n",
    "between variables. Ensure the summary is detailed and includes both numerical and textual descriptions. \\n\"\"\"\n",
    "print(f\"Question 1: {question}\")\n",
    "\n",
    "import time\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\")  # Starting message\n",
    "time.sleep(2)  # A delay of 2 seconds\n",
    "print(\"Starting text generation...\\n\")\n",
    "\n",
    "# Getting the LLM's response\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": question})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 1: {response_text}\")\n",
    "\n",
    "# Asking the model another question\n",
    "print(\"\"\"\\nQuestion 2: Based on the analysis and summary from the previous prompt, create visualizations that effectively represent the unique \n",
    "trends, high correlations, and demographic information identified. Use appropriate chart types such as bar charts, scatter plots, and heatmaps \n",
    "to visualize the data. Include a brief description for each visualization explaining what it represents and the insights it provides. \\n\"\"\")\n",
    "\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"\"\"Based on the analysis and summary from the previous prompt, create \n",
    "visualizations that effectively represent the unique trends, high correlations, and demographic information identified. Use appropriate chart \n",
    "types such as bar charts, scatter plots, and heatmaps to visualize the data. Include a brief description for each visualization explaining what \n",
    "it represents and the insights it provides. \\n\"\"\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 2: {response_text}\")\n",
    "\n",
    "# Asking the model a follow-up question\n",
    "print(\"\"\"\\nQuestion 3: Generate a comprehensive report combining the detailed summary from the first \n",
    "prompt and the visualizations from the second prompt. Ensure the report is well-organized and includes the following sections: Introduction, Data \n",
    "Summary, Key Trends and Correlations, Demographic Insights, Visual Representations, and Conclusion. Additionally, provide Python code to export this \n",
    "report as a word file which can be easily editable. The code should include necessary libraries and ensure that the docx file is properly formatted with all visualizations embedded. \\n \\n\"\"\")\n",
    "\n",
    "print(\"\\n⭐ Initiating Intelligent Text Generation ⭐\\n\")\n",
    "time.sleep(2)\n",
    "response_dict = llm_chain.invoke({\"columns\": columns, \"question\": \"\"\"Generate a comprehensive report combining the detailed summary from the first \n",
    "prompt and the visualizations from the second prompt. Ensure the report is well-organized and includes the following sections: Introduction, Data \n",
    "Summary, Key Trends and Correlations, Demographic Insights, Visual Representations, and Conclusion. Additionally, provide Python code to export this \n",
    "report as a word file which can be easily editable. The code should include necessary libraries and ensure that the docx file is properly formatted with all visualizations embedded. \\n\"\"\"})\n",
    "response_text = response_dict[\"text\"]\n",
    "print(f\"Answer 3: {response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49303f0-9800-49ee-8053-bc963cdb2972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
